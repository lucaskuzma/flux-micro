# FLUX Micro: A Simplified Diffusion Transformer for CIFAR-10 (32×32)

## Introduction

Diffusion models have emerged as powerful generative models by _gradually adding noise to training images and then learning to reverse that process_ ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)). Recent advances like **Flux** (by Black Forest Labs) combine diffusion processes with Transformer architectures for high-fidelity image generation, scaling up to billions of parameters ([Flux (text-to-image model) - Wikipedia](<https://en.wikipedia.org/wiki/Flux_(text-to-image_model)#:~:text=Flux%20is%20a%20series%20of,25>)). **FLUX Micro** is a pared-down version of this idea – a minimal diffusion Transformer implemented in PyTorch, designed to run on a CPU (e.g., a Mac laptop). It targets 32×32 images (CIFAR-10) to demonstrate core concepts without requiring heavy computation. In this tutorial, we present the full implementation of FLUX Micro, including training and inference scripts, and explain the key concepts of diffusion Transformers that underlie the model.

## Key Concepts of Diffusion Transformers

- **Diffusion Model Basics**: A diffusion model is a two-step generative process consisting of a **forward (noising) phase** and a **reverse (denoising) phase** ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=1,space%20outside%20the%20data%20subspace)) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)). In the forward phase, noise is added to an image in small increments over $T$ time-steps until the image becomes pure noise. In the reverse phase, a model learns to gradually remove noise, step by step, to recover a clean image. During training, the model is given a noised image at a random time-step $t$ and tries to predict the _noise_ that was added, using a simple **mean squared error (MSE)** loss between the predicted noise and the actual noise ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=Image%3A%20The%20simplified%20loss%20function,DDPMs)). By predicting the noise, the model learns how to denoise the image for each level of corruption. At inference, we start from pure noise and apply the model iteratively from $t=T$ down to $t=0$ to generate a final image ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)).

- **Transformer Backbone vs U-Net**: Traditional image diffusion models (like Stable Diffusion) use a U-Net CNN to learn the denoising function. A diffusion Transformer replaces this U-Net backbone with a Transformer-based architecture ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=In%20a%20typical%20diffusion%20model%2C,the%20performance%20of%20diffusion%20models)). Transformers operate on sequences, so we first need to convert the 2D image into a sequence of tokens (one token per image patch or pixel) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=The%20model%20first%20inputs%20spatial,the%20transformer%20can%20process%20effectively)). For FLUX Micro, we treat each pixel (with its RGB values) as a token in a sequence of length 1024 (for a 32×32 image). The Transformer processes this sequence with self-attention, which allows the model to capture global relationships in the image, not just local pixel neighborhoods. This demonstrates that convolutional inductive biases (like locality in U-Nets) are not strictly necessary for diffusion model performance ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=In%20a%20typical%20diffusion%20model%2C,the%20performance%20of%20diffusion%20models)), although they help with efficiency. We use a **modest number of Transformer layers** (configurable, e.g. 8–12 for CPU training) to balance feasibility and output quality, whereas large diffusion Transformers may use dozens of layers (Flux models use 32–64 or more layers for higher fidelity at the cost of more computation).

- **Spatial Positional Embeddings**: Because the image is flattened into a sequence, we must encode the spatial structure so the Transformer knows which token corresponds to which location. We add a fixed or learnable **positional embedding** to each token that represents its (row, column) position in the 32×32 grid ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Positional%20Embeddings)). This way, the model can infer adjacency and image layout from the sequence. FLUX Micro uses learned positional embeddings for simplicity, though one could also use 2D sinusoidal embeddings.

- **Time-Step Conditioning**: The diffusion model’s denoising behavior must depend on the current time-step $t$ (how much noise is in the image). We incorporate the time-step as an additional conditioning input by converting $t$ into a vector (using a sinusoidal embedding or small MLP) and injecting it into the model ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)). In practice, we add a **time embedding** to the token embeddings (similar to how positional embeddings are added). This tells the Transformer _how far along_ in the diffusion process the input is, so it can remove the appropriate amount of noise. This technique is analogous to how U-Nets modulate their layers with time-step embeddings.

With these concepts, we can design the FLUX Micro architecture.

## Model Architecture: FLUX Micro

**FLUX Micro** follows a straightforward Transformer-based architecture for 32×32 image generation. The design is modular and simplified for clarity and CPU efficiency:

- **Input Embedding**: The input is a noised image of shape `(3,32,32)`. We flatten it to a sequence of length 1024 (each token corresponds to one pixel’s RGB) and project each 3-dimensional RGB vector to a higher-dimensional **embedding space** (e.g. 128). This is done via a linear layer.
- **Positional + Time Embeddings**: We add a learned positional embedding to each token to encode its spatial location ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Positional%20Embeddings)). We also add a time-step embedding to every token’s representation to encode the diffusion step. The time embedding is obtained by feeding $t$ (normalized to $[0, T]$) through sinusoidal position encoding or a small neural network to produce a vector of the same size as the token embeddings. This **conditions the Transformer on the noise level** of the input ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)).
- **Transformer Layers**: A stack of self-attention layers (multi-head attention + feed-forward network with residual connections) forms the core of the model ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=In%20a%20typical%20diffusion%20model%2C,the%20performance%20of%20diffusion%20models)). Each Transformer layer allows tokens to attend to each other, meaning the model can capture both local and long-range dependencies in the image. In FLUX Micro we use a smaller number of heads and layers (e.g., 4 heads, 8 layers by default) to keep computation light, but these can be increased for more capacity. Layer normalization is used for stable training.
- **Output Projection**: The Transformer outputs a sequence of the same length (1024 tokens, each of dimension 128). A final linear layer projects each token’s embedding back to 3 values, representing the predicted noise for that pixel (or alternatively the direct predicted RGB, but predicting noise is standard). We then reshape the sequence back to `(3,32,32)` image format.

This architecture is intentionally minimal. It omits advanced enhancements like adaptive layer normalization or cross-attention (which advanced models use for text conditioning or more efficient conditioning ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=%2A%20In,efficient%20adaptation))) – FLUX Micro is _unconditional_ and focuses on the basics: predicting noise for a given time-step and image. The following sections provide the implementation with code, organized for clarity and easy modification.

## Implementation

We will structure our implementation as a small Python package with modular components for ease of understanding and extension. The core components include the model definition, a diffusion scheduler for the noise process, a training script, and an inference (image sampling) script. All code is written in PyTorch and optimized for CPU-only execution.

### Model Definition (`flux_micro/model.py`)

Here is the full implementation of the FLUX Micro Transformer model. It includes the pixel embedding, positional/time embeddings, Transformer blocks, and output projection: [Flux Micro Model](flux_micro/model.py)

**Explanation:** In the code above, `FluxMicroModel` defines our diffusion Transformer. We use `nn.TransformerEncoderLayer` for the self-attention layers (with PyTorch’s `batch_first=True` so the sequence is of shape `(batch, seq, features)`). The `forward` method takes a noised image `x_noisy` and a time-step `t`. We flatten `x_noisy` and create token embeddings with `token_proj`. We then add **positional embeddings** (`self.pos_emb`) to encode each token’s position in the image grid ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Positional%20Embeddings)). Next, we generate a **time-step embedding** (`time_emb`) using a sinusoidal encoding for the input time $t$, and add this to the token embeddings (broadcasting it across all tokens) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)). The prepared sequence `x` is then passed through the Transformer encoder stack, which applies multi-head attention and feed-forward transformations across all tokens. Finally, `output_proj` maps the Transformer’s output back to three values per token (RGB noise). The output of `forward` has the same shape as the input image, representing the model’s predicted noise at time $t$ for each pixel.

This model is intentionally compact. You can easily adjust parameters like `embed_dim`, `num_layers`, or `num_heads` to explore trade-offs between speed and quality. For example, increasing `num_layers` towards the 32–64 range (as used in larger diffusion Transformers) might improve generation fidelity at the cost of speed and memory.

### Diffusion Schedule and Utilities (`flux_micro/diffusion_utils.py`)

The diffusion process requires defining a noise schedule $\beta_1, \beta_2, \ldots, \beta_T$ which controls how much noise is added at each step. A common schedule is to linearly increase $\beta_t$ from a small value to a larger value over $T$ steps (e.g., from 1e-4 to 0.02 over 1000 steps). From the $\beta$ schedule, we compute $\alpha_t = 1 - \beta_t$ and the cumulative products $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$. These values are used both in training (to generate noisy images) and in inference (to progressively denoise). Here is a utility snippet to prepare the diffusion coefficients and to add noise to an image at a given time-step: [Flux Micro Diffusion Utilities](flux_micro/diffusion_utils.py)

Here, `make_diffusion_schedule` computes the schedule and returns tensors for $\sqrt{\bar{\alpha}_t}$ and $\sqrt{1-\bar{\alpha}_t}$ for all $t$. The function `add_noise` uses these to take a batch of original images `x0` (assumed to be scaled to [-1, 1]) and a batch of time indices `t`, and returns the noised images `x_t` along with the noise that was added. We’ll use these in the training loop. (Note: We choose $T=1000$ by default, as is common in diffusion models ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=Image%3A%20The%20simplified%20loss%20function,DDPMs)), but for quicker training you could use a smaller $T`, like 200 or 500.)

### Training Script (`scripts/train.py`)

Here is an example training script for FLUX Micro on CIFAR-10. It ties together the model and diffusion utilities, and demonstrates a simple training loop on CPU. The batch size and number of epochs should be kept small for practicality on a Mac CPU. [Flux Micro Training Script](scripts/train.py)

**Notes:** We use `torchvision.datasets.CIFAR10` with a transform that resizes images to 32×32 and scales pixel values to [-1,1]. During each training iteration, we sample a random diffusion step `t` for each image and create a noised image `x_t` using `add_noise`. The model predicts the noise, and we calculate the MSE loss against the true noise that was used ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=Image%3A%20The%20simplified%20loss%20function,DDPMs)). Over time, this trains the model to remove the correct amount of noise for each step. We print the loss periodically for monitoring. Training a diffusion model is time-intensive; on a CPU, one epoch over CIFAR-10 (50k images) with this model might take a long time, so consider training on a subset or for fewer epochs to see intermediate results. Even with few epochs, the model may start to denoise simple patterns, but full training for quality samples could take many hours on CPU.

### Inference Script (`scripts/sample.py`)

Once the model is trained (or at least has learned some noise-removal capability), we can generate images by simulating the reverse diffusion process. We start from pure noise and iteratively apply the model to denoise step-by-step. Here is an example inference script that loads a saved model (if you saved model state dict) and generates new images: [Flux Micro Inference Script](scripts/sample.py)

In the sampling process, we implement the reverse diffusion formula from the DDPM paper. For each time-step $t$ from $T$ down to 1, the model predicts the noise $\epsilon_{\theta}(x_t, t)$ for the current noisy image. We then compute the estimated denoised image $x_0$ (at the current step) and the mean for the distribution of $x_{t-1}$ ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=Image%3A%20%24%24%5Cmu_,bar%7B%5Calpha_%7Bt%7D%7D%7D%7D%20%5Cepsilon_%7B%5Ctheta%7D%28x_%7Bt%7D%2C%20t%29%20%5Cright)) ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=Image%3A%20The%20simplified%20loss%20function,DDPMs)). We add random Gaussian noise according to the variance $\beta_t$ to sample $x_{t-1}$. By the end of the loop, we obtain $x_0$ which should be an image approximately drawn from the learned data distribution. Since our model outputs images in [-1,1], we scale the final output back to [0,1] for saving/viewing. The script uses `torchvision.utils.save_image` to save the generated image, and then opens it using PIL. On a CPU, sampling 1000 steps for a 32×32 image is slow but manageable (each step involves one forward pass of the Transformer).

**Tip:** You can reduce the number of diffusion steps (say, use $T=200$) for faster sampling/training at the cost of somewhat lower quality, or use an optimized sampler (like DDIM or fewer steps with larger noise removal per step) once the model is trained.

## Conclusion and Further Exploration

In this guide, we designed **FLUX Micro**, a simplified diffusion Transformer tailored for 32×32 images. We covered the key ideas: using a Transformer encoder in place of a CNN to model image generation ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=In%20a%20typical%20diffusion%20model%2C,the%20performance%20of%20diffusion%20models)), flattening images into token sequences ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=The%20model%20first%20inputs%20spatial,the%20transformer%20can%20process%20effectively)) with positional embeddings ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Positional%20Embeddings)), and conditioning on diffusion time-steps to guide the denoising process ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)). The implementation is modular, with clear separation between the model, diffusion schedule, training loop, and sampling procedure, making it easy to adjust or extend.

While FLUX Micro is capable of learning and generating tiny images on a CPU, its output quality will be limited by the small model size and dataset. Nevertheless, it demonstrates the core mechanics of diffusion Transformers in a manageable setting. To improve results, one could increase the model size (more layers or embedding dimensions), train for more epochs, or introduce advanced conditioning (for example, class-conditioning on CIFAR-10 classes or text-conditioning like the full Flux models). This scaled-down model serves as a stepping stone for understanding diffusion Transformers, and the same principles can be applied to larger architectures or higher resolutions as computational resources allow. Happy experimenting with diffusion Transformers!

**Sources:** Diffusion model and transformer concepts adapted from research on diffusion probabilistic models and diffusion Transformers ([InDepth Guide to Denoising Diffusion Probabilistic Models DDPM](https://learnopencv.com/denoising-diffusion-probabilistic-models/#:~:text=Image%3A%20The%20simplified%20loss%20function,DDPMs)) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=In%20a%20typical%20diffusion%20model%2C,the%20performance%20of%20diffusion%20models)) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=The%20model%20first%20inputs%20spatial,the%20transformer%20can%20process%20effectively)) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Positional%20Embeddings)) ([Scalability of Diffusion Models with Transformer Backbone | Encord](https://encord.com/blog/diffusion-models-with-transformers/#:~:text=Training%20and%20Inference)), and inspired by the Flux series of models ([Flux (text-to-image model) - Wikipedia](<https://en.wikipedia.org/wiki/Flux_(text-to-image_model)#:~:text=Flux%20is%20a%20series%20of,25>)) which combine these techniques at scale.
